{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_Character_based_text_generation_code_using_rnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7b2Z9UBfGn2",
        "colab_type": "text"
      },
      "source": [
        "Importing all the libraries to be used in code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OFl0AAxS8JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdfI6bdWfLTz",
        "colab_type": "text"
      },
      "source": [
        "Reading the Text file on which we will train our RNN model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qoM0OI5TNod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=open(\"/content/sonnets.txt\").read()\n",
        "text=text.lower()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzZwrkHKfUIv",
        "colab_type": "text"
      },
      "source": [
        "Creating a dictionary of characters which are present in the text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tVGR3bUTern",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars=sorted(list(set(text)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfuNTBS_fagG",
        "colab_type": "text"
      },
      "source": [
        "Making two lists:\n",
        "1> from characters to index\n",
        "2> from index to characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02MGRuK2TmiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars_to_ix={ch:i for i,ch in enumerate(chars)}\n",
        "ix_to_chars={i:ch for i,ch in enumerate(chars)}\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvKosEfcfjth",
        "colab_type": "text"
      },
      "source": [
        "**Generating Two arrays of type text, one for input(sequences) and one for output(target)**\n",
        "\n",
        "Seq_length determine the time steps which we use in RNN LSTM block\n",
        "\n",
        "We use a many to one prediction model:\n",
        "for example text is \"I am awesome\" and seq_length is 4\n",
        "\n",
        "\"i am\" produces \" \"\n",
        "\" am \" produces \"a\"\n",
        "\"am a\" produces \"w\"\n",
        "\"m aw\" produces \"e\"\n",
        "... so on\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUos12kRTyOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00df1f70-9668-4094-dc5c-aeefdc56d573"
      },
      "source": [
        "seq_length=100\n",
        "step=1\n",
        "\n",
        "sequences=[]\n",
        "targets=[]\n",
        "for i in range(0,len(text)-seq_length,step):\n",
        "  sequences.append(text[i:i+seq_length])\n",
        "  targets.append(text[i+seq_length])\n",
        "print(len(sequences))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BSssFz9hpko",
        "colab_type": "text"
      },
      "source": [
        "Vectorizing the data:\n",
        "creating input matrix X and output matrix Y from sequences and target respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4L46qArUAP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.zeros((len(sequences),seq_length,len(chars)))\n",
        "Y=np.zeros((len(sequences),len(chars)))\n",
        "\n",
        "for i in range(len(sequences)):\n",
        "  sentence=sequences[i]\n",
        "  for j,ch in enumerate(sentence):\n",
        "    X[i,j,chars_to_ix[ch]]=1\n",
        "  Y[i,chars_to_ix[targets[i]]]=1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqC_u1KSh9GZ",
        "colab_type": "text"
      },
      "source": [
        "Creating the a simple model:Adding LSTM layer and a Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbDPTxcgVGLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "4f6c3999-d817-4476-a108-54df8c8a746d"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(128,input_shape=(seq_length,len(chars))))\n",
        "model.add(Dense(len(chars),activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               86016     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 39)                5031      \n",
            "=================================================================\n",
            "Total params: 91,047\n",
            "Trainable params: 91,047\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhptmCrEi96K",
        "colab_type": "text"
      },
      "source": [
        "Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfWF_xcSXbRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk9WBQB2i__T",
        "colab_type": "text"
      },
      "source": [
        "Sample function defined for sampling the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUWrYZRrXthD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds,temperature=1.0):\n",
        "  preds=np.asarray(preds).astype('float64')\n",
        "  preds=np.log(preds)/temperature\n",
        "  exp_preds=np.exp(preds)\n",
        "  preds=exp_preds/np.sum(exp_preds)\n",
        "  probas=np.random.multinomial(1,preds,1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsCzVseljLEu",
        "colab_type": "text"
      },
      "source": [
        "Finally text will be generated by calling the generate_output function, with total characters: seq_length+600"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d3ZIh3VYL4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "def generate_output(temp):\n",
        "  start_idx=np.random.randint(0,len(text)-seq_length-1)\n",
        "  output_text=text[start_idx:start_idx+seq_length]\n",
        "  sys.stdout.write(output_text)\n",
        "\n",
        "  for i in range(600):\n",
        "    sampled=np.zeros((1,seq_length,len(chars)))\n",
        "    for i,ch in enumerate(output_text):\n",
        "      sampled[0,i,chars_to_ix[ch]]=1\n",
        "    probs=model.predict(sampled,verbose=0)[0]\n",
        "    pred_idx=sample(probs,temperature=temp)\n",
        "    next_char=ix_to_chars[pred_idx]\n",
        "\n",
        "    output_text+=next_char\n",
        "    output_text=output_text[1:]\n",
        "\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc7ZCn6LjcmD",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLUO-l9oZfk6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "881008b1-23bd-412c-880c-c2e24ec570c6"
      },
      "source": [
        "model.fit(X,Y,batch_size=128,epochs=20)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.4512\n",
            "Epoch 2/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.4357\n",
            "Epoch 3/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.4218\n",
            "Epoch 4/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.4081\n",
            "Epoch 5/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.3943\n",
            "Epoch 6/20\n",
            "747/747 [==============================] - 8s 11ms/step - loss: 1.3811\n",
            "Epoch 7/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.3693\n",
            "Epoch 8/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.3561\n",
            "Epoch 9/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.3439\n",
            "Epoch 10/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.3320\n",
            "Epoch 11/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.3192\n",
            "Epoch 12/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.3075\n",
            "Epoch 13/20\n",
            "747/747 [==============================] - 8s 11ms/step - loss: 1.2954\n",
            "Epoch 14/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.2836\n",
            "Epoch 15/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.2727\n",
            "Epoch 16/20\n",
            "747/747 [==============================] - 8s 11ms/step - loss: 1.2617\n",
            "Epoch 17/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.2508\n",
            "Epoch 18/20\n",
            "747/747 [==============================] - 9s 11ms/step - loss: 1.2408\n",
            "Epoch 19/20\n",
            "747/747 [==============================] - 8s 11ms/step - loss: 1.2292\n",
            "Epoch 20/20\n",
            "747/747 [==============================] - 8s 11ms/step - loss: 1.2198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbcad94a940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsmA_ARqjfLB",
        "colab_type": "text"
      },
      "source": [
        "Finally the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp-hwERSZjsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "a289ce9f-61f0-47ed-cc3b-e67662b6b684"
      },
      "source": [
        "generate_output(0.77)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " of worth, what worth in you doth grow.\n",
            "this silence for my sin you did impute,\n",
            "which shall be most and winteing her graces:\n",
            "the ounding sweet invention stranged dears.\n",
            "\n",
            "lxxxii.\n",
            "\n",
            "o, me, the congol, that gunds and how can pine\n",
            "which, i seem but in the worse, which you were,\n",
            "hath leath, your come than hath me rememmer'd\n",
            "age streast,, when thou says are now devire?\n",
            "and me, yourself in days of your thee reads,\n",
            "if such since my still shall me a true,\n",
            "whilst i as youth, when i time which new;\n",
            "but those bained that when to straight,\n",
            "  age in this pity of thy sun mast from thee,\n",
            "and youtherome that which not figst mine eyes,\n",
            "though in thus do i as is sovel;\n",
            "but dear thou, full negear still reseet sa"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAXLVcNWcmxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
